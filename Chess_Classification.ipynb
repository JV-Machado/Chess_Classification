{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JV-Machado/Chess_Classification/blob/master/Chess_Classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AbLcUrQp2Vow",
        "outputId": "d43a94b9-40de-4543-9e93-de0b968b9d17"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UKCb7Rex2Xmm"
      },
      "outputs": [],
      "source": [
        "import zipfile\n",
        "with zipfile.ZipFile('/content/drive/MyDrive/TCC/Chess-image-dataset.zip', 'r') as zip_ref:\n",
        "    zip_ref.extractall('/content/drive/MyDrive/TCC/Folder_Chess_Dataset')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Organização dos dados**"
      ],
      "metadata": {
        "id": "Nv834WQ9Q3No"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i1U1woj83wnR"
      },
      "outputs": [],
      "source": [
        "import glob\n",
        "from shutil import copyfile\n",
        "import os\n",
        "\n",
        "imgs = glob.glob(\"/content/drive/MyDrive/TCC/Folder_Chess_Dataset/Chess-image-dataset/*/*\")\n",
        "for img in imgs:\n",
        "  class_name = img.split(\"/\")[-2][0:]\n",
        "  img_name = img.split(\"/\")[-1][0:]\n",
        "  copyfile(img, f'/content/drive/MyDrive/TCC/data/-{class_name}-{img_name}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DxBxE35I2X_w"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import glob\n",
        "\n",
        "imgs_path = glob.glob('/content/drive/MyDrive/TCC/data/*')\n",
        "lista = []\n",
        "\n",
        "for img_path in imgs_path:\n",
        "  name = img_path.split('-')[-2][0:]\n",
        "  # img = img_path.split('-')[-1][0:]\n",
        "  lista.append([img_path, name])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YKPa7vQY2YSg"
      },
      "outputs": [],
      "source": [
        "df = pd.DataFrame(columns=[\"Image_Path\", \"Image_Class\"], data=lista)\n",
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6Co7J6EbBdf7"
      },
      "outputs": [],
      "source": [
        "categories = pd.factorize(df['Image_Class'])[1]\n",
        "print(categories)\n",
        "df['Image_Class'] = pd.factorize(df['Image_Class'])[0]\n",
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iSIsh1G72Ytm",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "ee29d8a5-bf94-4504-984c-2cd76b3e7bd3"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'cuda'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "from google.colab.patches import cv2_imshow\n",
        "import torch\n",
        "from PIL import Image\n",
        "from torch.utils.data import DataLoader,Dataset\n",
        "import os\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "device"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zMCBR3h22ZM6"
      },
      "outputs": [],
      "source": [
        "import torchvision\n",
        "from torchvision import transforms\n",
        "from torchvision.datasets import ImageFolder\n",
        "import os\n",
        "\n",
        "preprocess = transforms.Compose([\n",
        "    transforms.Resize((100,100)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(\n",
        "        (0.6741, 0.6644, 0.6534), \n",
        "        (0.3837, 0.3853, 0.3900))\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uIVjaSIp_A7c"
      },
      "outputs": [],
      "source": [
        "class ImageDataset(Dataset):\n",
        "    def __init__(self, df, transform = None):\n",
        "        self.df = df\n",
        "        self.transform = transform\n",
        "        \n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "    \n",
        "    def __getitem__(self, index):\n",
        "        image = Image.fromarray(cv2.cvtColor(cv2.imread(self.df.iloc[index,0]),cv2.COLOR_BGR2RGB))\n",
        "        image=self.transform(image)\n",
        "        y = torch.tensor(int(self.df.iloc[index,1]))\n",
        "\n",
        "        return image, y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MTnf16UT_CIg"
      },
      "outputs": [],
      "source": [
        "train_dataset = ImageDataset(df, transform = preprocess)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xyf853tfABQY"
      },
      "outputs": [],
      "source": [
        "# imgs = torch.stack([img_t for img_t, _ in train_dataset], dim=3)\n",
        "# imgs.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IlKFe-GRAB9u"
      },
      "outputs": [],
      "source": [
        "# imgs.view(3, -1).mean(dim=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eY1-zv2AAFTV"
      },
      "outputs": [],
      "source": [
        "# imgs.view(3, -1).std(dim=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b4IjFykb_Grt"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data.dataloader import DataLoader\n",
        "from torch.utils.data import random_split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a61-rM45C5wh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1a2249d9-b6ed-4a96-f3cc-bbe2c24ece96"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Length of Train Data : 521\n",
            "Length of Validation Data : 130\n"
          ]
        }
      ],
      "source": [
        "validation_data_size = round(0.20*(len(train_dataset)))\n",
        "# test_data_size = round(0.2*(len(train_dataset)))\n",
        "train_data_size = len(train_dataset) - validation_data_size \n",
        "\n",
        "train_data, validation_data  = random_split(train_dataset, [train_data_size, validation_data_size])\n",
        "print(f\"Length of Train Data : {len(train_data)}\")\n",
        "# print(f\"Length of Test Data : {len(test_data)}\")\n",
        "print(f\"Length of Validation Data : {len(validation_data)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ygXLuSpG_Jkc"
      },
      "outputs": [],
      "source": [
        "batch_size = 16\n",
        "\n",
        "train_DL = DataLoader(train_data, batch_size, shuffle = True)\n",
        "# test_DL = DataLoader(test_data, batch_size, shuffle = True)\n",
        "validation_DL = DataLoader(validation_data, batch_size, shuffle = True)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Treinamento com CNN**"
      ],
      "metadata": {
        "id": "tG1ZawhURKct"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_NkhSdq9_Ly1"
      },
      "outputs": [],
      "source": [
        "from torchvision import datasets, models, transforms\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bDDFhN4n_QXJ"
      },
      "outputs": [],
      "source": [
        "def train_loop(model, dataloader, loss_func, optimizer):\n",
        "    model.train()\n",
        "    cumloss = 0.0\n",
        "    running_accuracy = 0.0\n",
        "\n",
        "    for i, data in enumerate(dataloader):\n",
        "        imgs, labels = data\n",
        "    \n",
        "        imgs, labels = imgs.to(device), labels.to(device)\n",
        "    \n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        pred = model(imgs)\n",
        "\n",
        "        loss = loss_func(pred, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        cumloss += loss.item()\n",
        "        \n",
        "        ps = F.softmax(pred,-1)\n",
        "        top_p, top_class = ps.topk(k = 1, dim = 1)\n",
        "        equals = top_class == labels.view(*top_class.shape)\n",
        "\n",
        "        accuracy = torch.mean(equals.type(torch.float))\n",
        "\n",
        "        running_accuracy += accuracy\n",
        "\n",
        "    return cumloss / len(dataloader), running_accuracy/len(dataloader)\n",
        "\n",
        "def validate(model, dataloader, loss_func):\n",
        "    model.eval()\n",
        "    cumloss = 0.0\n",
        "    running_accuracy_val = 0.0\n",
        "    with torch.no_grad():\n",
        "        for imgs, labels in dataloader:\n",
        "            imgs, labels = imgs.to(device), labels.to(device)\n",
        "\n",
        "            pred = model(imgs)\n",
        "            loss = loss_func(pred, labels)\n",
        "            cumloss += loss.item()\n",
        "\n",
        "            ps = F.softmax(pred,-1)\n",
        "            top_p, top_class = ps.topk(k = 1, dim = 1)\n",
        "            equals = top_class == labels.view(*top_class.shape)\n",
        "\n",
        "            accuracy_val = torch.mean(equals.type(torch.float))\n",
        "\n",
        "            running_accuracy_val += accuracy_val\n",
        "\n",
        "        return cumloss / len(dataloader), running_accuracy_val/len(dataloader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_WfW8xkk_RSJ"
      },
      "outputs": [],
      "source": [
        "model_ft = models.vgg16(pretrained=True)\n",
        "model_ft = model_ft.to(device)\n",
        "loss_func = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(model_ft.parameters(), lr=0.001)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yViWUtob_TtG"
      },
      "outputs": [],
      "source": [
        "num_features = models.vgg16().classifier[6].in_features\n",
        "model_ft.fc = nn.Linear(num_features, 5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nRu3fLna_Yg_"
      },
      "outputs": [],
      "source": [
        "epochs = 25\n",
        "conv_train_losses = []\n",
        "conv_test_losses = []\n",
        "for t in range(epochs):\n",
        "    train_loss, acc_train = train_loop(model_ft, train_DL, loss_func, optimizer)\n",
        "    conv_train_losses.append(train_loss)\n",
        "    print(f\"\\rEpoch: {t}; Train Loss: {train_loss} Accuracy train: {acc_train}\")\n",
        "    test_loss, acc_test = validate(model_ft, validation_DL, loss_func)\n",
        "    conv_test_losses.append(test_loss)\n",
        "    print(f\"\\rEpoch: {t}; Validate Loss: {test_loss} Accuracy validation: {acc_test}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Matriz de Confusão**"
      ],
      "metadata": {
        "id": "E5F7TasFRgyj"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D-TFjg5J3BsS"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "\n",
        "y_pred = []\n",
        "y_true = []\n",
        "nb_classes = 5\n",
        "\n",
        "confusion_matrix = torch.zeros(nb_classes, nb_classes)\n",
        "\n",
        "for imgs, labels in validation_DL:\n",
        "  imgs, labels = imgs.to(device), labels.to(device)\n",
        "\n",
        "  pred = model_ft(imgs)\n",
        "\n",
        "  _, preds = torch.max(pred, 1)\n",
        "  for t, p in zip(labels.view(-1), preds.view(-1)):\n",
        "    confusion_matrix[t.long(), p.long()] += 1\n",
        "\n",
        "print(confusion_matrix)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gpn0RyP65k9y"
      },
      "outputs": [],
      "source": [
        "class_names = list(categories)\n",
        "df_cm = pd.DataFrame(confusion_matrix, index=class_names, columns=class_names).astype(int)\n",
        "heatmap = sns.heatmap(df_cm, annot=True, fmt=\"d\")\n",
        "\n",
        "heatmap.yaxis.set_ticklabels(heatmap.yaxis.get_ticklabels(), rotation=0, ha='right',fontsize=15)\n",
        "heatmap.xaxis.set_ticklabels(heatmap.xaxis.get_ticklabels(), rotation=45, ha='right',fontsize=15)\n",
        "plt.ylabel('True label')\n",
        "plt.xlabel('Predicted label')"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP/YcmBZLI6e0kGtc+VBrzA",
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}